# ì•ˆë“œë¡œì´ë“œ ì¹´ë©”ë¼ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ object detection

[ğŸ”¢ìˆ«ì ë¶„ë¥˜ Android Appë§Œë“¤ê¸°](../0924_Android(ViewDrawingDigitClassifier)/1_ê¸°ê¸°ë°°í¬-ViewDrawingDigitClassifier.md)

### ì‹¤ì‹œê°„ìœ¼ë¡œ ì´¬ì˜í•œ ì´ë¯¸ì§€ë¥¼ ê°€ì§€ê³  ML

- ì•ˆë“œë¡œì´ë“œì˜ ê²½ìš°ëŠ” ë™ì˜ìƒ ì´¬ì˜ì„ ìœ„í•´ì„  SurfaceView ë‚˜ TextureViewì˜ ê°œë…ì„ ì•Œì•„ì•¼ í•¨.
- ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€ê²½ë˜ëŠ” ì´ë¯¸ì§€ë¥¼ ì¶œë ¥í•˜ë ¤ë©´ Open GLì´ë‚˜ Direct Xë¥¼ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤.
  - Open GL
    - ìŠ¤ë§ˆíŠ¸í°ì—ì„œëŠ” OpenGL ES
    - ì›¹ì—ì„œëŠ” Web GL
    - ìœˆë„ìš°ì¦ˆë¥¼ ì œì™¸í•œ ìš´ì˜ì²´ì œì˜ ê·¸ë˜í”½ ê°€ì† ê¸°ìˆ 
  - Direct X
    - ìœˆë„ìš°ì¦ˆì˜ ê·¸ë˜í”½ ê°€ì† ê¸°ìˆ 
- ìŠ¤ë§ˆíŠ¸í° APIì—ëŠ” ì €ëŸ° ê¸°ìˆ ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë˜í•‘ëœ APIê°€ ì œê³µë©ë‹ˆë‹¤
- C++ì— ëŒ€í•œ í•™ìŠµì´ ì„ í–‰ë˜ì–´ìˆì–´ì•¼ í•©ë‹ˆë‹¤
- iOSì—ì„œëŠ” ë³„ë„ì˜ APIë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- Open GL ì„ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì–´ë µê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ê¸° ì‰½ë„ë¡ í•´ì£¼ëŠ” í”„ë ˆì„ì›Œí¬ë¡œ ìœ ëª…í•œ 2ê°€ì§€ëŠ” C# ê¸°ë°˜ì˜ Unity ì™€ C++ ê¸°ë°˜ì˜ Unrealì´ ìˆìŠµë‹ˆë‹¤.
  - í˜„ì¬ëŠ” ìŠ¤ë§ˆíŠ¸í°ì—ì„œ unrealì„ ì“°ë©´ ë§ˆì¼“ì—ì„œ reject ì‚¬ìœ ê°€ ë©ë‹ˆë‹¤. 
- ê·¸ë˜í”½ ê°€ì† ê¸°ìˆ ì…ë‹ˆë‹¤.

#### ìŠ¤ë ˆë“œ

ìŠ¤ë ˆë“œì˜ ê°œë…ì„ ë°˜ë“œì‹œ í•™ìŠµí•´ì•¼ í•©ë‹ˆë‹¤.

ì•ˆë“œë¡œì´ë“œëŠ” ìŠ¤ë˜ë“œì™€ í•¸ë“¤ëŸ¬ì— ê°œí•œ ê°œë…ì„ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤.

ì‚¬ì§„ì°ê¸° - ì €ì¥ëœ ì‚¬ì§„ìœ¼ë¡œ ì¸ì‹í•˜ê¸°

ìì—°ì–´ ì²˜ë¦¬ ë°ì´í„°ê°€ ìŒ“ì´ë©´ ëª¨ë¸í›ˆë ¨ ì¬ìˆ˜í–‰

#### ë°°ì¹˜ì²˜ë¦¬

ì„œë²„ìª½ì€ ìœˆë„ìš°ê°€ ë§ì§€ ì•Šê³  ë¦¬ëˆ…ìŠ¤ë‚˜ ìœ ë‹‰ìŠ¤ë¥¼ ë§ì´ ì“°ëŠ”ë° shell ëª…ë ¹ì„ ã…ã…‚ë‹

ì›¹ì—ì„œ í¬ë¡¤ë§í•´ì„œ ìš´ì˜ì²´ì œì—ì„œ êµ¬í˜„í•˜ëŠ” ê²ƒì´ë¼ë©´ , ë°°ì¹˜ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ê³µë¶€í•´ì„œ ì ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤

### ë™ì  ê¶Œí•œ ì·¨ë“

ìŠ¤ë§ˆíŠ¸í°ì€ ê°œì¸ì •ë³´ë¥¼ ì €ì¥í•˜ê³  ìˆê³  ê³µìš©ë°ì´í„°ì— ëª¨ë“  ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì ‘ê·¼í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ìŠ¤ë§ˆíŠ¸í°ì´ ì œê³µí•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì•„ë‹Œ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ê³µìš© ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” ê²½ìš°ëŠ” ì ì ˆí•œ ê¶Œí•œì„ ì‚¬ìš©ìê°€ ë¶€ì—¬í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

ì •ì  ê¶Œí•œ : ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì„¤ì¹˜í•  ë•Œ ë‚˜ ì²˜ìŒ ì‹¤í–‰í•  ë•Œ í•œ ë²ˆë§Œ ê¶Œí•œì— ëŒ€í•œ ìš”ì²­ì„ í•˜ëŠ” ë°©ì‹

ë™ì  ê¶Œí•œ : ì• í”Œë¦¬ì¼€ì´ì„  ì‹¤í–‰ì‹œë§ˆë‹¤ ê¶Œí•œì„ ìš”ì²­í•˜ëŠ” ë°©ì‹

AndroidMenifest.xmlì—ì„œ ê¶Œí•œì„ ì„¤ì •í•˜ê³  ì²˜ìŒ ì‹¤í–‰í•  ë•Œ ê¶Œí•œìš”ì²­ì„ í•˜ê³  ê·¸ ë’¤ë¡œ ì•ˆí–ˆì§€ë§Œ Cameraì˜ ê²½ìš° ,ë™ì ìœ¼ë¡œ ê¶Œí•œì„ ìš”ì²­í•˜ë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤.

ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•˜ëŠ” í˜•íƒœë¡œ êµ¬í˜„ì„ ë§ì´ í•©ë‹ˆë‹¤.



## [Application Desing Pattern](../0902_python_WebService(Django)%2C%20RL/Django_Framework.md#2applcitaion-desing-patternê°œë°œ-ë°©ì‹)

MVC(Model View Controller) : í”„ë¡œê·¸ë¨ì„ ì—­í• ë³„ë¡œ ë¶„í• í•˜ì—¬ êµ¬í˜„í•˜ëŠ” ê²ƒìœ¼ë¡œ ë””ìì¸íŒ¨í„´ì´ ì•„ë‹ˆë¼ ì•„í‚¤í…ì²˜ì— ê´€í•œ ê²ƒì…ë‹ˆë‹¤. 

- Design Pattern : ê°ì²´ ì§€í–¥ ì–¸ì–´ì—ì„œ class ë¥¼ ì–´ë–»ê²Œ ì„¤ê³„í•  ê²ƒì¸ê°€ í•˜ëŠ” ë¬¸ì œ, Gofì˜ ë””ìì¸ íŒ¨í„´
- ì•„í‚¤í…ì²˜ : í´ë˜ìŠ¤ë‚˜ í´ë˜ìŠ¤ ë˜ëŠ” Device ë“±ì˜ ê´€ì 



MVVM (View, View Model)

 ìŠ¤ë§ˆíŠ¸í°ì—ì„œ ì‚¬ìš©í•˜ëŠ” êµ¬ì¡° íŒ¨í„´í™œìš©. 

í•˜ë‚˜ì˜ ëª¨ë¸ í•˜ë‚˜ì˜ Activity

ì´ í˜•íƒœë¡œ ë§Œë“¤ë©´ ì—¬ëŸ¬ê°€ì§€ ì—­í• ì„ í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ê²Œ ë  ë•Œ ë§ì€ Activityê°€ í•„ìš”í•˜ê³  ì´ê²ƒì€ ìì›ì˜ ë‚­ë¹„ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

activityëŠ” Componentì´ë©° ìƒì„± ì‹œì ì„ ìš°ë¦¬ê°€ ì•Œ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ë©”ëª¨ë¦¬ ê´€ë¦¬ê°€ ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤. 

ResourceëŠ” ì•±ì´ ì‹¤í–‰ë  ë•Œ ì „ë¶€ ë©”ëª¨ë¦¬ì— ë¡œë“œê°€ ë©ë‹ˆë‹¤.

Activityê°€ ì—¬ëŸ¬ê°œê°€ ë˜ë©´ ë©”ëª¨ë¦¬ê´€ë¦¬ê°€ í˜ë“¤ì–´ì§‘ë‹ˆë‹¤.

assets  í° ê·¸ë¦¼

resourceì—ëŠ” ì‘ì€ ê·¸ë¦¼



### ğŸ“Œ ì•ˆë“œë¡œì´ë“œì˜ Fragment

- í•˜ë‚˜ì˜ Activityì—ì„œ ë‹¤ë¥¸ Activity ë¡œ ì „í™˜ë  ë•Œ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ ëŠì–´ì§€ë©´ ì•„ë¬´ê²ƒë„ ì¶œë ¥í•˜ì§€ ëª»í•˜ëŠ”ê²½ìš°ë„ ë°œìƒí•©ë‹ˆë‹¤.

- í•˜ë‚˜ì˜ í™”ë©´ì—ì„œ ë°ì´í„°ë¥¼ ë³€ê²½í•´ê°€ë©´ì„œ ì¶œë ¥ì´ ê°€ëŠ¥í•œ êµ¬ì¡°ë¥¼ ìƒê°í–ˆê³  View ë‚˜ Layout ë“±ìœ¼ë¡œ ê°€ëŠ¥í•˜ì§€ë§Œ ViewëŠ” ìˆ˜ëª…ì£¼ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ëª…ì£¼ê¸°ê°€ ì—†ë‹¤ëŠ” ê²ƒì€ ë©”ëª¨ë¦¬ ê´€ë¦¬ê°€ ì–´ë µë‹¤ëŠ” ê²ƒì´ê³  ì–´ë–¤ VIewê°€ ë³´ì—¬ì§€ê³  ì‚¬ë¼ì§€ë„ë¡ í•˜ëŠ” ê²ƒì´ ì–´ë µìŠµë‹ˆë‹¤.

- ì‚¬ìš©ì€ Viewì²˜ëŸ¼í•˜ê³  ìˆ˜ëª…ì£¼ê¸°ë¥¼ ê°–ëŠ” í´ë˜ìŠ¤ë¥¼ ìƒê°í•˜ê²Œ ë˜ì—ˆëŠ”ë° ê·¸ê²ƒì´ ì•ˆë“œë¡œì´ë“œì˜ Fragmentì…ë‹ˆë‹¤. (Webì—ì„œì˜ ajax)

 



# 1.í”„ë¡œì íŠ¸ ìƒì„±



# 2.tflite ì˜ì¡´ì„± ì¶”ê°€

tfliteëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ tensorflow lite ì„¤ì •ì„ module ìˆ˜ì¤€ì˜ build.gradleì— ì¶”ê°€í•©ë‹ˆë‹¤.

module ìˆ˜ì¤€ì˜ build.gradle

```
implementation 'org.tensorflow:tensorflow-lite:2.4.0'
implementation 'org.tensorflow:tensorflow-lite-support:0.1.0'
```



# 3.ğŸ“ƒtfliteëª¨ë¸ ì¶”ê°€



## 1) ğŸ“‚assets ë””ë ‰í† ë¦¬ ìƒì„±

í”„ë¡œì íŠ¸ ì˜¤ë¥¸ìª½ í´ë¦­- [New]- [Folder]- [Assets Folder]ì„ í´ë¦­í•˜ì—¬ assets ë””ë ‰í† ë¦¬ë¥¼ ì˜¬ë°”ë¥¸ ê²½ë¡œì— ìƒì„±í•©ë‹ˆë‹¤.  ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ í‹€ë¦¬ì§€ ì•Šì•„ ì§ì ‘ í´ë”ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ì•ˆì „í•©ë‹ˆë‹¤.



## 2) ğŸ“ƒtfliteëª¨ë¸ì„ ğŸ“‚assetsì— ë¶™ì—¬ë„£ê¸°ğŸ’¦

ì´ë¯¸ì§€ë¶„ë¥˜ë¥¼ ìœ„í•œ tflite ëª¨ë¸ì„ ğŸ“‚assets ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜ì‹œí‚µë‹ˆë‹¤.

- tflite ëª¨ë¸ : [ë¶„ë¥˜ëª¨ë¸ê³¼ ì¶œë ¥ì„ ìœ„í•œ ë ˆì´ë¸” íŒŒì¼]()



ğŸ“ƒtfliteíŒŒì¼ì˜ ìœ„ì¹˜

```
app
â””â”€â”€â”€ğŸ“assets
	â””â”€â”€â”€ğŸ“ƒmobilenet_imagenet_model.tflite
```



# 4.ì¹´ë©”ë¼ ì‚¬ìš©ì„ ìœ„í•œ ê¶Œí•œ ì¶”ê°€

AndroidManifest.xmlì— ë‹¤ìŒê³¼ ê°™ì€ ì¹´ë©”ë¼ ì‚¬ìš©ê¶Œí•œì„ ì¶”ê°€í•´ì¤ë‹ˆë‹¤.



AndroidManifest.xml

```xml
<uses-feature android:name="android.hardware.camera" android:required="true" />
<uses-permission android:name="android.permission.CAMERA" />
```



# 5.ğŸ“„Classifier.java : ì¶”ë¡  

ì†ŒìŠ¤ íŒŒì¼ : 

## 1) ğŸ“„Classifier.java ìƒì„±ìœ„ì¹˜

```
app
â””â”€â”€â”€ğŸ“java
    â””â”€â”€â”€ğŸ“„Classifier.java
```



## 2) ì „ì²´ ì†ŒìŠ¤

```java
package com.lpin.realtime_camera;

import android.content.Context;
import android.graphics.Bitmap;
import android.util.Pair;
import android.util.Size;

import org.tensorflow.lite.Tensor;
import org.tensorflow.lite.support.common.FileUtil;
import org.tensorflow.lite.support.common.ops.NormalizeOp;
import org.tensorflow.lite.support.image.ImageProcessor;
import org.tensorflow.lite.support.image.TensorImage;
import org.tensorflow.lite.support.image.ops.ResizeOp;
import org.tensorflow.lite.support.image.ops.ResizeWithCropOrPadOp;
import org.tensorflow.lite.support.image.ops.Rot90Op;
import org.tensorflow.lite.support.label.TensorLabel;
import org.tensorflow.lite.support.model.Model;
import org.tensorflow.lite.support.tensorbuffer.TensorBuffer;
import static org.tensorflow.lite.support.image.ops.ResizeOp.ResizeMethod.NEAREST_NEIGHBOR;

import java.io.IOException;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class Classifier {
    
    //  ì¶”ë¡ ì„ ìœ„í•œ 2ê°œì˜ íŒŒì¼ì˜ ì´ë¦„ì„ ìƒìˆ˜ë¡œ ì„¤ì •
    private static final String MODEL_NAME = "mobilenet_imagenet_model.tflite";
    private static final String LABEL_FILE = "labels.txt";

    // ì•±ë‚´ì˜ ìì›ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì¸ìŠ¤í„´ìŠ¤ ì°¸ì¡° ë³€ìˆ˜
    Context context;
    
    // ì¶”ë¡ ì„ í•˜ê¸° ìœ„í•œ ì¸ìŠ¤í„´ìŠ¤ ì°¸ì¡° ë³€ìˆ˜
    Model model;
    
    // ì¶”ë¡ ì„ ìœ„í•´ì„œ ì‚¬ìš©í•  ì…ë ¥ì— ê´€í•œ ë³€ìˆ˜
    // ì „ì²˜ë¦¬ë¥¼ ìœ„í•´ ì‚¬ìš©
    int modelInputWidth, modelInputHeight, modelInputChannel;
    TensorImage inputImage;
    
    // ì¶”ë¡  ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ë³€ìˆ˜
    TensorBuffer outputBuffer;
    
    // ì¶”ë¡  ê²°ê³¼ í•´ì„ì„ ìœ„í•´ì„œ ë ˆì´ë¸” íŒŒì¼ì˜ ë‚´ìš©ì„ ì €ì¥í•  ë³€ìˆ˜
    private List<String> labels;
    // ì´ˆê¸°í™” ìˆ˜í–‰ ì—¬ë¶€ë¥¼ ì €ì¥í•  ë³€ìˆ˜
    private boolean isInitialized = false;

    // Classifier ìƒì„±ì
    // Context ë§Œ ë„˜ê²¨ë°›ì•„ì„œ ëŒ€ì…í•©ë‹ˆë‹¤.
    public Classifier(Context context) {
        this.context = context;
    }

    // ì´ˆê¸°í™” ë©”ì†Œë“œ
    public void init() throws IOException {
        // ëª¨ë¸ ìƒì„±
        model = Model.createModel(context, MODEL_NAME);
        // ì…ì¶œë ¥ ê´€ë ¨ ë°ì´í„°ë¥¼ ì„¤ì •í•˜ëŠ” ë©”ì†Œë“œ í˜¸ì¶œ
        initModelShape();
        // ë ˆì´ë¸” íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ì˜µë‹ˆë‹¤.
        labels = FileUtil.loadLabels(context, LABEL_FILE);
        // ì´ˆê¸°í™”ë¥¼ ìˆ˜í–‰í–ˆë‹¤ê³  í‘œì‹œ
        isInitialized = true;
    }

    // ì´ˆê¸°í™” ì—¬ë¶€ë¥¼ ì €ì¥í•œ ë³€ìˆ˜ë¥¼ ë¦¬í„´í•˜ëŠ” ë©”ì†Œë“œ
    public boolean isInitialized() {
        return isInitialized;
    }

    // ì…ì¶œë ¥ ì •ë³´ë¥¼ ì„¤ì •í•˜ê¸° ìœ„í•œ ë©”ì†Œë“œ
    private void initModelShape() {
        // ëª¨ë¸ì˜ ì…ë ¥ ë°ì´í„°ì— ëŒ€í•œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        Tensor inputTensor = model.getInputTensor(0);
        
        // ì…ë ¥ë°ì´í„°ì˜ ëª¨ì–‘ì„ ë³€ìˆ˜ì— ì €ì¥
        int[] shape = inputTensor.shape();
        modelInputChannel = shape[0];
        modelInputWidth = shape[1];
        modelInputHeight = shape[2];
        
        // ì…ë ¥ë°ì´í„° ëª¨ì–‘ì„ ì„¤ì •
        inputImage = new TensorImage(inputTensor.dataType());

        // ì¶œë ¥ ë°ì´í„° ëª¨ì–‘ì„ ì„¤ì •
        Tensor outputTensor = model.getOutputTensor(0);
        outputBuffer = TensorBuffer.createFixedSize(outputTensor.shape(),
                outputTensor.dataType());
    }
    
    // ì…ë ¥ì— ì‚¬ìš©í•  ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ë¦¬í„´í•˜ëŠ” ë©”ì†Œë“œ
    public Size getModelInputSize() {
        if (!isInitialized)
            return new Size(0, 0);
        return new Size(modelInputWidth, modelInputHeight);
    }

    // Android ì¹´ë©”ë¼ë¡œ ì´¬ì˜í•œ ì´ë¯¸ì§€ë¥¼ ì¶”ë¡ ì— ë§ëŠ” í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ëŠ” ë©”ì†Œë“œ
    private Bitmap convertBitmapToARGB8888(Bitmap bitmap) {
        return bitmap.copy(Bitmap.Config.ARGB_8888, true);
    }

    // 
    private TensorImage loadImage(final Bitmap bitmap, int sensorOrientation) {
        // í˜•ì‹ë³€í™˜
        if (bitmap.getConfig() != Bitmap.Config.ARGB_8888) {
            inputImage.load(convertBitmapToARGB8888(bitmap));
        } else {
            inputImage.load(bitmap);
        }
        // ìë¥¼ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ì„¤ì •
        // ìµœì†Ÿê°’ì˜ í¬ê¸°ë¥¼ ì°¾ì•„ì„œ ì´ë¯¸ì§€ë¥¼ ìµœì†Ÿê°’ í¬ê¸°ì— ë§ëŠ” ì •ì‚¬ê°í˜•ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•´ì„œ   
        int cropSize = Math.min(bitmap.getWidth(), bitmap.getHeight());
        // íšŒì „ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì •
        int numRotation = sensorOrientation / 90;

        // ì´ë¯¸ì§€ ì „ì²˜ë¦¬

        ImageProcessor imageProcessor = new ImageProcessor.Builder()
                // 1. ì´ë¯¸ì§€ í™•ëŒ€ ì¶•ì†Œ - ì •ì‚¬ê°í˜•ì¸ì§€ ì§ì‚¬ê°í˜•ì¸ì§€ì— ë”°ë¼ ë‹¤ë¥´ë¯€ë¡œ ë…¼ë¬¸ì„ ì½ì–´ë´ì•¼ í•©ë‹ˆë‹¤.
                // ì´ë¯¸ì§€ ì¡ìŒì´ ë“¤ì–´ê°€ë¯€ë¡œ ì‘ì€ ì‚¬ì´ì¦ˆì— ë§ì¶°ì„œ í•´ì•¼ë¨.
                // í™•ëŒ€ì˜ ê²½ìš°ëŠ” paddingìœ¼ë¡œ ì˜†ì˜ ë°ì´í„°ë¥¼ ì„¤ì •í•˜ë¯€ë¡œ ì¡ìŒì´ í™•ëŒ€ ë ìˆ˜ë„ ì‡ìŒ
                // ì§ì‚¬ê°í˜•ì´ë©´ í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
                .add(new ResizeWithCropOrPadOp(cropSize, cropSize))
                // 2. ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆì¡°ì •
                .add(new ResizeOp(modelInputWidth, modelInputHeight, NEAREST_NEIGHBOR))
                // 3. íšŒì „
                .add(new Rot90Op(numRotation))
                // 4. ì •ê·œí™” - ì „ì´ í•™ìŠµì„ í•˜ëŠ” ê²½ìš°ëŠ” ë…¼ë¬¸ì„ ì½ì–´ë´ì•¼ í•©ë‹ˆë‹¤.
                .add(new NormalizeOp(0.0f, 255.0f))
                .build();
        return imageProcessor.process(inputImage);
    }

    // ì¶”ë¡  ë©”ì†Œë“œ
    public Pair<String, Float> classify(Bitmap image, int sensorOrientation) {
        // ì…ë ¥ë°ì´í„° ìƒì„±
        inputImage = loadImage(image, sensorOrientation);
        
        Object[] inputs = new Object[]{inputImage.getBuffer()};
        Map<Integer, Object> outputs = new HashMap();
        outputs.put(0, outputBuffer.getBuffer().rewind());
        // ì¶”ë¡ 
        model.run(inputs, outputs);
        // ì¶”ë¡  ê²°ê³¼ë¥¼ ì €ì¥
        Map<String, Float> output =
                new TensorLabel(labels, outputBuffer).getMapWithFloatValue();
        // ì¶”ë¡  ê²°ê³¼ë¥¼ í•´ì„í•˜ëŠ” ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•´ì„œ ë¦¬í„´
        return argmax(output);
    }

    // ê¸°ê¸° ë°©í–¥ì´ ì—†ì„ ë•Œ ì¶”ë¡ í•˜ëŠ” ë©”ì†Œë“œ
    public Pair<String, Float> classify(Bitmap image) {
        return classify(image, 0);
    }
    
    // ì¶”ë¡  ê²°ê³¼ í•´ì„ ë©”ì†Œë“œ
    // ì¶”ë¡ ì„ í•˜ë©´ í´ë˜ìŠ¤ì˜ ë ˆì´ë¸”ì´ ë¦¬í„´ë˜ì§€ ì•Šê³  ì¸ë±ìŠ¤ê°€ ë¦¬í„´ë˜ë¯€ë¡œ
    // ì¸ë±ìŠ¤ë¥¼ ë ˆì´ë¸”ë¡œ ë³€ê²½í•˜ê³  ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë°ì´í„°ë§Œ ì¶”ì¶œ
    private Pair<String, Float> argmax(Map<String, Float> map) {
        String maxKey = "";
        float maxVal = -1;
        for (Map.Entry<String, Float> entry : map.entrySet()) {
            float f = entry.getValue();
            if (f > maxVal) {
                maxKey = entry.getKey();
                maxVal = f;
            }
        }
        return new Pair<>(maxKey, maxVal);
    }

    // ë©”ëª¨ë¦¬ ì •ë¦¬í•˜ëŠ” ë©”ì†Œë“œ
    public void finish() {
        if (model != null) {
            model.close();
            isInitialized = false;
        }
    }

}
```





# 6.AutoFitTextureView.java : ë™ì˜ìƒ ë¯¸ë¦¬ë³´ê¸°
ë™ì˜ìƒ ë¯¸ë¦¬ë³´ê¸° ë¥¼ ì œê³µí•˜ëŠ” TextureView í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ëŠ” í´ë˜ìŠ¤ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

### ğŸ“Œ TextureView ì™€ SurfaceView

- [TextureView ì™€ SurfaceViewì— ëŒ€í•œ ê°œë…](https://source.android.google.cn/devices/graphics/arch-tv?hl=ko)

- TextureView
  - ì—°ì†ì ì¸ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ê°’ë“¤ê³¼ ê°™ì´ ì¹´ë©”ë¼ë¥¼ ì´ìš©í•œ ë¬´ì–¸ê°€ì˜ ê¸°ëŠ¥ì„ ë§Œë“¤ì–´ ë‚¼ ë•Œ ì‚¬ìš©í•˜ëŠ” ë·°. ex) ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤, ì‹¤ì‹œê°„ ì–¼êµ´ ì¸ì‹
- SurfaceView
  - ì´ë¯¸ì§€ í”„ë¡œì„¸ì‹±ê³¼ ê´€ë ¨ëœ ê¸°ëŠ¥ì„ ë§Œë“¤ì–´ ë·°ì˜ ê³„ì¸µ êµ¬ì¡° ë‚´ë¶€ì— surfaceë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ ì „ìš© Viewë‹¤.  ex) ì‚¬ì§„ ë³´ì •

- ì´ì „ì—ëŠ” SurfaceViewë§Œ ì œê³µì´ ë˜ì—ˆëŠ”ë° ì§€ê¸ˆì€ SurfaceViewë³´ë‹¤ ì•ŒíŒŒë‚˜ íšŒì „ì²˜ë¦¬ê°€ ë›°ì–´ë‚œ TextureViewë„ ì œê³µë©ë‹ˆë‹¤.
- ë™ì˜ìƒ í•©ì„±ì„ í•  ë•ŒëŠ” SurfaceViewê°€ ì„±ëŠ¥ì´ ë›°ì–´ë‚©ë‹ˆë‹¤.



## 1) ğŸ“„AutoFitTextureView.java ìƒì„±ìœ„ì¹˜

```
app
â””â”€â”€â”€ğŸ“java
    â””â”€â”€â”€ğŸ“„AutoFitTextureView.java
    â””â”€â”€â”€ğŸ“„Classifier.java
```





## 2) ì „ì²´ ì†ŒìŠ¤ğŸ’¦

```java
package com.lpin.realtime_camera;

import android.content.Context;
import android.util.AttributeSet;
import android.view.TextureView;

public class AutoFitTextureView extends TextureView {

    // ê°€ë¡œ ì„¸ë¡œ í¬ê¸° ì €ì¥í•  ë³€ìˆ˜
    private int ratioWidth = 0;
    private int ratioHeight = 0;

    // ìƒì„±ì
    // ìƒì„±ìë¥¼ ë§Œë“œëŠ” ê²½ìš°ì˜ ëŒ€ë¶€ë¶„ì€ ë³„ë„ì˜ ì´ˆê¸°í™” ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ ì í•˜ëŠ” ê²½ìš°
    // ìƒì„±ìë¥¼ ë°˜ë“œì‹œ ë§Œë“¤ì–´ì•¼ í•˜ëŠ” ê²½ìš° : ìƒìœ„ í´ë˜ìŠ¤ì— ë§¤ê°œë³€ìˆ˜ê°€ ì—†ëŠ” ìƒì„±ìê°€ ì—†ëŠ” ê²½ìš°ì…ë‹ˆë‹¤.
    public AutoFitTextureView(final Context context) {
        this(context, null);
    }
    public AutoFitTextureView(final Context context, final AttributeSet attrs) {
        this(context, attrs, 0);
    }
    public AutoFitTextureView(final Context context, final AttributeSet attrs, final int defStyle) {
        super(context, attrs, defStyle);
    }

    // ê°€ë¡œì„¸ê³ 
    public void setAspectRatio(final int width, final int height) {
        if (width < 0 || height < 0) {
            throw new IllegalArgumentException("Size cannot be negative.");
        }
        ratioWidth = width;
        ratioHeight = height;
        // ë ˆì´ì•„ì›ƒì„ ë‹¤ì‹œ ê·¸ë ¤ë‹¬ë¼ê³  í•˜ëŠ” ë©”ì†Œë“œ í˜¸ì¶œ
        requestLayout();
    }

    // í™”ë©´ì´ ë‹¤ì‹œ ê·¸ë ¤ì§ˆ ë•Œ í™”ë©´ì˜ í¬ê¸°ë¥¼ ì„¤ì •í•˜ê¸° ìœ„í•´ì„œ í˜¸ì¶œë˜ëŠ” ë©”ì†Œë“œ
    // onDraq ë‚˜ onPaint ëŠ” ë‹¤ì‹œ ê·¸ë¦¬ëŠ” ë©”ì†Œë“œ
    // onMeasure ëŠ” í¬ê¸°ë¥¼ ì„¤ì •í•˜ëŠ” ë©”ì†Œë“œ
    @Override
    protected void onMeasure(final int widthMeasureSpec, final int heightMeasureSpec) {
        super.onMeasure(widthMeasureSpec, heightMeasureSpec);
        final int width = MeasureSpec.getSize(widthMeasureSpec);
        final int height = MeasureSpec.getSize(heightMeasureSpec);
        if (0 == ratioWidth || 0 == ratioHeight) {
            setMeasuredDimension(width, height);
        } else {
            // ë†’ì´ê°€ ë„ˆë¹„ë³´ë‹¤ í¬ë©´ ë„ˆë¹„ë¡œ ì„¤ì •
            if (width < height * ratioWidth / ratioHeight) {
                setMeasuredDimension(width, width * ratioHeight / ratioWidth);
            } else {
                // ë„ˆë¹„ê°€ í¬ë©´ ë†’ì´ë¡œ ì„¤ì •
                setMeasuredDimension(height * ratioWidth / ratioHeight, height);
            }
        }
    }

}
```





### ìƒì„±ì ë©”ì†Œë“œ

- ëŒ€ë¶€ë¶„ì€ ë³„ë„ì˜ ì´ˆê¸°í™” ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³ ì í•˜ëŠ” ê²½ìš° ìƒì„±ìë¥¼ ë§Œë“­ë‹ˆë‹¤.
- ìƒìœ„ í´ë˜ìŠ¤ì— ë§¤ê°œë³€ìˆ˜ê°€ ì—†ëŠ” ìƒì„±ìê°€ ì—†ëŠ” ê²½ìš°ì—” ìƒì„±ìë¥¼ ë°˜ë“œì‹œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.

```java
// ìƒì„±ì
public AutoFitTextureView(final Context context) {
    this(context, null);
}
```



### onMeasure(int, int)

onMeasure ëŠ” TextureViewì—ì„œ ì œê³µí•˜ëŠ”ë° í¬ê¸°ë¥¼ ì„¤ì •í•˜ëŠ” ë©”ì†Œë“œì…ë‹ˆë‹¤.

- ê·¸ ë°–ì—ë„ onDraq ë‚˜ onPaint ëŠ” ë‹¤ì‹œ ê·¸ë¦¬ëŠ” ë©”ì†Œë“œì…ë‹ˆë‹¤.

- onMeasureì— ëŒ€í•œ ì„¤ëª… : [https://developer.android.com/reference/android/view/View#onMeasure(int,%20int)](https://developer.android.com/reference/android/view/View#onMeasure(int,%20int))



```java
// í™”ë©´ì´ ë‹¤ì‹œ ê·¸ë ¤ì§ˆ ë•Œ í™”ë©´ì˜ í¬ê¸°ë¥¼ ì„¤ì •í•˜ê¸° ìœ„í•´ì„œ í˜¸ì¶œë˜ëŠ” ë©”ì†Œë“œ
@Override
protected void onMeasure(final int widthMeasureSpec, final int heightMeasureSpec) {
    super.onMeasure(widthMeasureSpec, heightMeasureSpec);
    final int width = MeasureSpec.getSize(widthMeasureSpec);
    final int height = MeasureSpec.getSize(heightMeasureSpec);
    if (0 == ratioWidth || 0 == ratioHeight) {
        setMeasuredDimension(width, height);
    } else {
        // ë†’ì´ê°€ ë„ˆë¹„ë³´ë‹¤ í¬ë©´ ë„ˆë¹„ë¡œ ì„¤ì •
        if (width < height * ratioWidth / ratioHeight) {
            setMeasuredDimension(width, width * ratioHeight / ratioWidth);
        } else {
            // ë„ˆë¹„ê°€ í¬ë©´ ë†’ì´ë¡œ ì„¤ì •
            setMeasuredDimension(height * ratioWidth / ratioHeight, height);
        }
    }
}
```







# 7.YuvToRGBConverter.java : í¬ë§· ë³€í™˜

### ğŸ“Œ YuvToRGBConverter.java

ì•ˆë“œë¡œì´ë“œê°€ ì´¬ì˜í•œ Yuv í¬ë§·ì˜ ì´ë¯¸ì§€ë¥¼ RGB í¬ë§·ìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” í´ë˜ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

- ì´ í´ë˜ìŠ¤ëŠ” êµ¬ê¸€ì—ì„œ kotlinìœ¼ë¡œ ìƒ˜í”Œ ì½”ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤
- ì†ŒìŠ¤ë¥¼ ë³µì‚¬í•  ë•Œ javaë¥¼ kotlinìœ¼ë¡œ ë³€í™˜í•  ê²ƒì¸ì§€ ë¬¼ì–´ë³´ê³  ë³€í™˜ ì†ŒìŠ¤ë„ ì œê³µí•©ë‹ˆë‹¤.
- kotlin ì½”ë“œì™€ Java ëŠ” Android Studio ë‚˜ Intelli Jì—ì„œ ì„œë¡œ ê°„ì— ë³€í™˜ì´ ë©ë‹ˆë‹¤.
- êµ¬ê¸€ì€ ì•ˆë“œë¡œì´ë“œì— ëŒ€í•œ API ì§€ì›ì„ ì•ìœ¼ë¡œ Kotlinìœ¼ë¡œë§Œ ì œê³µí•©ë‹ˆë‹¤.



### ğŸ“Œ kotlin

ë„¤ì´ë²„ëŠ” ë°±ì—”ë“œ ìŠ¤í”„ë§ ê°œë°œì— kotlinì„ ì‚¬ìš©í•˜ë©°, ì¤‘ê²¬ ê¸°ì—…ë“¤ì€ ì„œë²„ë¥¼ êµ¬ì¶•í•  ë•Œ kotlin ì´ë‚˜ node.js ë¥¼ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤.



## 1) YuvToRGBConverter.java ìƒì„± ìœ„ì¹˜

```
app
â””â”€â”€â”€ğŸ“java
    â””â”€â”€â”€ğŸ“„AutoFitTextureView.java
	â””â”€â”€â”€ğŸ“„Classifier.java
	â””â”€â”€â”€ğŸ“„MainActivity.java
	â””â”€â”€â”€ğŸ“„YuvToRGBConverter.java
```





## 2) ì „ì²´ ì†ŒìŠ¤

```java
package com.lpin.realtime_camera;

import android.content.Context;
import android.graphics.Bitmap;
import android.graphics.ImageFormat;
import android.graphics.Rect;
import android.media.Image;
import android.renderscript.Allocation;
import android.renderscript.Element;
import android.renderscript.RenderScript;
import android.renderscript.ScriptIntrinsicYuvToRGB;
import android.renderscript.Type;

import java.nio.ByteBuffer;

public class YuvToRGBConverter {
    private static void imageToByteArray(Image image, byte[] outputBuffer, int pixelCount) {
        assert image.getFormat() == ImageFormat.YUV_420_888;
        Rect imageCrop = image.getCropRect();
        Image.Plane[] imagePlanes = image.getPlanes();
        for(int planeIndex = 0; planeIndex < imagePlanes.length; planeIndex++) {
            Image.Plane plane = imagePlanes[planeIndex];
            int outputStride;
            int outputOffset;
            switch (planeIndex) {
                case 0: {
                    outputStride = 1;
                    outputOffset = 0;
                    break;
                }
                case 1: {
                    outputStride = 2;
                    outputOffset = pixelCount + 1;
                    break;
                }
                case 2: {
                    outputStride = 2;
                    outputOffset = pixelCount;
                    break;
                }
                default: {
                    return;
                }
            }
            ByteBuffer planeBuffer = plane.getBuffer();
            int rowStride = plane.getRowStride();
            int pixelStride = plane.getPixelStride();
            Rect planeCrop;
            if (planeIndex == 0) {
                planeCrop = imageCrop;
            } else {
                planeCrop = new Rect(
                        imageCrop.left / 2,
                        imageCrop.top / 2,
                        imageCrop.right / 2,
                        imageCrop.bottom / 2
                );
            }
            int planeWidth = planeCrop.width();
            int planeHeight = planeCrop.height();
            byte[] rowBuffer = new byte[plane.getRowStride()];
            int rowLength;
            if (pixelStride == 1 && outputStride == 1) {
                rowLength = planeWidth;
            } else {
                rowLength = (planeWidth - 1) * pixelStride + 1;
            }
            for(int row = 0; row < planeHeight; row++){
                planeBuffer.position(
                        (row + planeCrop.top) * rowStride + planeCrop.left * pixelStride);
                if (pixelStride == 1 && outputStride == 1) {
                    planeBuffer.get(outputBuffer, outputOffset, rowLength);
                    outputOffset += rowLength;
                } else {
                    planeBuffer.get(rowBuffer, 0, rowLength);
                    for (int col = 0; col < planeWidth; col++) {
                        outputBuffer[outputOffset] = rowBuffer[col * pixelStride];
                        outputOffset += outputStride;
                    }
                }
            }
        }
    }
    public static void yuvToRgb(Context context, Image image, Bitmap output) {
        RenderScript rs = RenderScript.create(context);
        ScriptIntrinsicYuvToRGB scriptYuvToRgb =
                ScriptIntrinsicYuvToRGB.create(rs, Element.U8_4(rs));
        int pixelCount = image.getCropRect().width() * image.getCropRect().height();
        int pixelSizeBits = ImageFormat.getBitsPerPixel(ImageFormat.YUV_420_888);
        byte[] yuvBuffer = new byte[pixelCount * pixelSizeBits / 8];
        imageToByteArray(image, yuvBuffer, pixelCount);
        Type elemType = new Type.Builder(rs, Element.YUV(rs))
                .setYuvFormat(ImageFormat.NV21)
                .create();
        Allocation inputAllocation =
                Allocation.createSized(rs, elemType.getElement(), yuvBuffer.length);
        Allocation outputAllocation = Allocation.createFromBitmap(rs, output);
        inputAllocation.copyFrom(yuvBuffer);
        scriptYuvToRgb.setInput(inputAllocation);
        scriptYuvToRgb.forEach(outputAllocation);
        outputAllocation.copyTo(output);
    }
}
```



# 8.fragment_camera.xml : Fragment ë ˆì´ì•„ì›ƒ

ë©”ì¸í™”ë©´ì˜ ì¼ë¶€ë¶„ìœ¼ë¡œ ì‚¬ìš©í•  Fragmentë¥¼ ìœ„í•œ ë ˆì´ì•„ì›ƒ íŒŒì¼ì„ ìƒì„±í•˜ê³  ì‘ì„±í•©ë‹ˆë‹¤. 

## 1) fragment_camera.xml ìƒì„± ìœ„ì¹˜

res/layout  ìš°í´ë¦­ - New - Layout Resource File í´ë¦­ 

filename : fragment_camera.xml

```
app
â””â”€â”€â”€ğŸ“res
	â””â”€â”€â”€ğŸ“layout
	    â””â”€â”€â”€ğŸ“„activity_main.xml
    	â””â”€â”€â”€ğŸ“„fragment_camera.xml			# ìƒì„±
```



## 2) ì „ì²´ ì†ŒìŠ¤

```xml
<?xml version="1.0" encoding="utf-8"?>
<FrameLayout xmlns:android="http://schemas.android.com/apk/res/android"
    android:layout_width="match_parent"
    android:layout_height="match_parent">

    <com.lpin.realtime_camera.AutoFitTextureView
        android:layout_width="match_parent"
        android:layout_height="match_parent"
        android:id="@+id/autoFitTextureView" />
</FrameLayout>
```

Viewê°€ í•˜ë‚˜ë°–ì— ì—†ìœ¼ë¯€ë¡œ LinearLayoutì´ë‚˜ FrameLayoutì´ë‚˜ ìƒê´€ì—†ìŠµë‹ˆë‹¤.



# 9.CameraFragment.java : 

fragment_camera.xml ì„ ì‚¬ìš©í•˜ëŠ” Fragment í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ëŠ” í´ë˜ìŠ¤ ìƒì„±

ì´ì „ì— ë§Œë“  TextureView ë¥¼ MainActivity í´ë˜ìŠ¤ì— ì¶œë ¥í•˜ëŠ” ì—­í• 



## 1) CameraFragment.java ìƒì„± ìœ„ì¹˜

```
app
â””â”€â”€â”€ğŸ“java
    â””â”€â”€â”€ğŸ“„AutoFitTextureView.java
    â””â”€â”€â”€ğŸ“„CameraFragment.java				# ìƒì„±
	â””â”€â”€â”€ğŸ“„Classifier.java
	â””â”€â”€â”€ğŸ“„MainActivity.java
	â””â”€â”€â”€ğŸ“„YuvToRGBConverter.java
```



## 2) ì „ì²´ ì†ŒìŠ¤

```java
package com.lpin.realtime_camera;

import android.annotation.SuppressLint;
import android.app.Activity;
import android.content.Context;
import android.content.res.Configuration;
import android.graphics.ImageFormat;
import android.graphics.Matrix;
import android.graphics.RectF;
import android.graphics.SurfaceTexture;
import android.hardware.camera2.CameraAccessException;
import android.hardware.camera2.CameraCaptureSession;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraDevice;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.CameraMetadata;
import android.hardware.camera2.CaptureRequest;
import android.hardware.camera2.params.StreamConfigurationMap;
import android.media.ImageReader;
import android.os.Bundle;
import android.os.Handler;
import android.os.HandlerThread;
import android.util.Size;
import android.view.LayoutInflater;
import android.view.Surface;
import android.view.TextureView;
import android.view.View;
import android.view.ViewGroup;
import android.widget.Toast;

import androidx.annotation.NonNull;
import androidx.annotation.Nullable;
import android.app.Fragment;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;

@SuppressLint("ValidFragment")
public class CameraFragment extends Fragment {
    // ë¡œê·¸ ì¶œë ¥í•  ë•Œ íƒœê·¸ë¥¼ ìƒìˆ˜ë¡œ ì§€ì •
    public static final String TAG = "[IC]CameraFragment";

    // ì¼ë°˜ì ìœ¼ë¡œ Callbackì´ë‚˜ Listenerë¼ëŠ” ìš©ì–´ëŠ” ì´ë²¤íŠ¸ê°€ ë°œìƒí–ˆì„ ë•Œ
    // ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ë‚˜ í´ë˜ìŠ¤ ë˜ëŠ” ì¸í„°í˜ì´ìŠ¤ì— ë¶™ì´ëŠ” ë‹¨ì–´ì…ë‹ˆë‹¤.
    // íŠ¹íˆ Listener ëŠ” javaì—ì„œëŠ” Interfaceë¡œ í•œì •í•©ë‹ˆë‹¤.
    // ì´ ê²½ìš° êµ¬í˜„í•´ì•¼ í•¨ëŠ” ë©”ì†Œë“œê°€ í•˜ë‚˜ë¼ë©´ lambdaë¡œ ëŒ€ì²´ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤ã…£
    // -> ë¼ëŠ” í‘œí˜„ì´ ë³´ì´ë©´ lambdaì…ë‹ˆë‹¤.
    private ConnectionCallback connectionCallback;
    private ImageReader.OnImageAvailableListener imageAvailableListener;

    // ì¹´ë©”ë¼ í¬ê¸°
    private Size inputSize;
    // ì¹´ë©”ë¼ ì•„ì´ë””
    // 0 : í›„ë©´ì¹´ë©”ë¼, 1: ì „ë©´ ì¹´ë©”ë¼
    private String cameraId;
    
    // ë™ì˜ìƒ ì¶œë ¥í•˜ê¸° ìœ„í•œ ì‚¬ìš©ì ì •ì˜ ë·°
    private AutoFitTextureView autoFitTextureView = null;

    // thread ì‚¬ìš©ì„ ìœ„í•œ ë³€ìˆ˜
    private HandlerThread backgroundThread = null;
    private Handler backgroundHandler = null;

    // ë¯¸ë¦¬ë³´ê¸° í¬ê¸°ì™€ ê¸°ê¸°ì˜ ë°©í–¥ì„ ì €ì¥í•  ë³€ìˆ˜
    private Size previewSize;
    private int sensorOrientation;

    // threadë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— multi thread í™˜ê²½ì—ì„œ ê³µìœ ìì›ì˜
    // ì‚¬ìš©ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì¸ìŠ¤í„´ìŠ¤
    // ì •ìˆ˜ëŠ” ìì›ì„ ë™ì‹œì— ì‚¬ìš©í•  thread ì˜ ê°œìˆ˜
    private final Semaphore cameraOpenCloseLock = new Semaphore(1);

    // ì¹´ë©”ë¼ ê´€ë ¨ ë³€ìˆ˜
    private CameraDevice cameraDevice;
    private CaptureRequest.Builder previewRequestBuilder;
    private ImageReader previewReader;
    private CameraCaptureSession captureSession;

    // ìƒì„±ìì˜ ì ‘ê·¼ ì§€ì •ì private : ì™¸ë¶€ì—ì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ì„ ëª»í•¨
    private CameraFragment(final ConnectionCallback callback,
                           final ImageReader.OnImageAvailableListener imageAvailableListener,
                           final Size inputSize,
                           final String cameraId) {
        this.connectionCallback = callback;
        this.imageAvailableListener = imageAvailableListener;
        this.inputSize = inputSize;
        this.cameraId = cameraId;
    }

    // ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ì„œ ë¦¬í„´í•´ì£¼ëŠ” static ë©”ì†Œë“œ - íŒ©í† ë¦¬ íŒ¨í„´
    // ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±ìë¥¼ ì´ìš©í•˜ì§€ ì•Šê³  ë³„ë„ì˜ ë©”ì†Œë“œì—ì„œ ìƒì„±
    // ê·¸ ì´ìœ ëŠ” ìƒì„±í•˜ëŠ” ê³¼ì •ì´ ë³µì¡í•´ì„œ ìƒì„±ìë¥¼ ë…¸ì¶œì‹œí‚¤ì§€ ì•Šê¸° ìœ„í•œ ëª©ì ê³¼ íš¨ìœ¨ì„ ìœ„í•´ì„œì„
    public static CameraFragment newInstance(
            final ConnectionCallback callback,
            final ImageReader.OnImageAvailableListener imageAvailableListener,
            final Size inputSize,
            final String cameraId) {
        return new CameraFragment(callback, imageAvailableListener, inputSize, cameraId);
    }
    // í™”ë©´ì„ ì¶œë ¥í•˜ê¸° ìœ„í•œ ë·°ë¥¼ ë§Œë“¤ ë•Œ í˜¸ì¶œë˜ëŠ” ë©”ì†Œë“œ
    // ë ˆì´ì•„ì›ƒ íŒŒì¼ì˜ ë‚´ìš©ë§Œ ë¶ˆëŸ¬ì„œ ë¦¬í„´
    @Override
    public View onCreateView(LayoutInflater inflater, ViewGroup container,
                             Bundle savedInstanceState) {
        return inflater.inflate(R.layout.fragment_camera, container, false);
    }

    // í™”ë©´ ì¶œë ¥ì´ ëœ í›„ í˜¸ì¶œë˜ëŠ” ë©”ì†Œë“œ
    // ë™ì˜ìƒ ë¯¸ë¦¬ë³´ê¸° viewë¥¼ ì°¾ì•„ì˜µë‹ˆë‹¤.
    @Override
    public void onViewCreated(@NonNull View view, @Nullable Bundle savedInstanceState) {
        autoFitTextureView = view.findViewById(R.id.autoFitTextureView);
    }

    // Activity ë‚˜ Fragment ê°€ í™”ë©´ì— ë³´ì—¬ì§ˆ ë•Œë§ˆë‹¤ í˜¸ì¶œë˜ëŠ” ë©”ì†Œë“œ
    // ìŠ¤ë ˆë“œë¥¼ ì‹œì‘
    // TextureView ê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ ì•Šìœ¼ë©´ ë¦¬ìŠ¤ë„ˆë¥¼ ì„¤ì •í•˜ê³ 
    // ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì¹´ë©”ë¼ì˜ ë‚´ìš©ì„ ì¶œë ¥
    @Override
    public void onResume() {
        super.onResume();
        startBackgroundThread();

        if(!autoFitTextureView.isAvailable())
            autoFitTextureView.setSurfaceTextureListener(surfaceTextureListener);
        else
            openCamera(autoFitTextureView.getWidth(), autoFitTextureView.getHeight());
    }

    // ì¶œë ¥ì´ ì¤‘ì§€ë  ë•Œ í˜¸ì¶œë˜ëŠ” ë©”ì†Œë“œ
    // ì¹´ë©”ë¼ë¥¼ ë‹«ê³  ìŠ¤ë ˆë“œë¥¼ ì¤‘ì§€
    @Override
    public void onPause() {
        closeCamera();
        stopBackgroundThread();
        super.onPause();
    }

    // ìŠ¤ë ˆë“œë¥¼ ìƒì„±í•´ì„œ ì‹œì‘í•˜ëŠ” ë©”ì†Œë“œ
    private void startBackgroundThread() {
        backgroundThread = new HandlerThread("ImageListener");
        backgroundThread.start();
        backgroundHandler = new Handler(backgroundThread.getLooper());
    }

    // ìŠ¤ë ˆë“œë¥¼ ì¤‘ì§€í•˜ëŠ” ë©”ì†Œë“œ
    private void stopBackgroundThread() {
        backgroundThread.quitSafely();
        try {
            backgroundThread.join();
            backgroundThread = null;
            backgroundHandler = null;
        } catch (final InterruptedException e) {
            e.printStackTrace();
        }
    }

    // TextureView ì˜ ë¦¬ìŠ¤ë„ˆ
    private final TextureView.SurfaceTextureListener surfaceTextureListener =
            new TextureView.SurfaceTextureListener() {
                // Texture ê°€ ìœ íš¨í•˜ë©´ í˜¸ì¶œë˜ëŠ” ë©”ì†Œë“œ
                @Override
                public void onSurfaceTextureAvailable(
                        final SurfaceTexture texture, final int width, final int height) {
                    openCamera(width, height);
                }
                // Texture ì˜ ì‚¬ì´ì¦ˆê°€ ë³€ê²½ë˜ë©´ íšŒì¶œë˜ëŠ” ë©”ì†Œë“œ
                // íšŒì „ì´ ë°œìƒí•˜ë©´ í˜¸ì¶œë˜ì–´ í¬ê¸°ê°€ ë°”ë€ŒëŠ”ê²Œ ì•„ë‹ˆë¼ ê°€ë¡œì™€ ì„¸ë¡œì˜ í¬ê¸°ê°€ ë°”ë€ë‹ˆë‹¤.
                @Override
                public void onSurfaceTextureSizeChanged(
                        final SurfaceTexture texture, final int width, final int height) {
                    configureTransform(width, height);
                }
                // Texture ê°€ ì†Œë©¸ë  ë•Œ í˜¸ì¶œë˜ëŠ” ë©”ì†Œë“œ
                @Override
                public boolean onSurfaceTextureDestroyed(final SurfaceTexture texture) {
                    return true;
                }
                // Texture ì˜ ë‚´ìš©ì´ ë³€ê²½ë  ë•Œ í˜¸ì¶œë˜ëŠ” ë©”ì†Œë“œ
                @Override
                public void onSurfaceTextureUpdated(final SurfaceTexture texture) {
                }
            };

    // ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ëŠ” ë©”ì†Œë“œ
    @SuppressLint("MissingPermission")
    private void openCamera(final int width, final int height) {
        // ì¹´ë©”ë¼ ì‚¬ìš© ê°ì²´ ì°¾ì•„ì˜¤ê¸°
        final Activity activity = getActivity();
        final CameraManager manager =
                (CameraManager)activity.getSystemService(Context.CAMERA_SERVICE);

        // ì¹´ë©”ë¼ë¥¼ ì„¤ì •í•˜ê³  í¬ê¸°ë¥¼ ì •ì˜í•˜ëŠ” ì‚¬ìš©ì ì •ì˜ ë©”ì†Œë“œë¥¼ í˜¸ì¶œ
        setupCameraOutputs(manager);
        configureTransform(width, height);

        try {
            // 2.5ì´ˆë™ì•ˆ ì¹´ë©”ë¼ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•˜ë©´ í™”ë©´ ì¤‘ì§€
            if (!cameraOpenCloseLock.tryAcquire(2500, TimeUnit.MILLISECONDS)) {
                Toast.makeText(getContext(),
                        "Time out waiting to lock camera opening.",
                        Toast.LENGTH_LONG).show();
                activity.finish();
            } else {
                // ì¹´ë©”ë¼ ì‚¬ìš©
                // cameraIdê°€ 0ì´ë©´ í›„ë©´ì¹´ë©”ë¼, 1ì´ë©´ ì „ë©´ ì¹´ë©”ë¼
                manager.openCamera(cameraId, stateCallback, backgroundHandler);
            }
        } catch (final InterruptedException | CameraAccessException e) {
            e.printStackTrace();
        }
    }

    // ì¹´ë©”ë¼ ì„¤ì •í•˜ëŠ” ë©”ì†Œë“œ
    // ìˆ˜ì •í•  ë¶€ë¶„ì´ ê±°ì˜ ì—†ìŒ
    private void setupCameraOutputs(CameraManager manager) {
        try {
            final CameraCharacteristics characteristics = manager.getCameraCharacteristics(cameraId);

            final StreamConfigurationMap map =characteristics.get(
                    CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);

            sensorOrientation = characteristics.get(CameraCharacteristics.SENSOR_ORIENTATION);

            previewSize = chooseOptimalSize(
                    map.getOutputSizes(SurfaceTexture.class),
                    inputSize.getWidth(),
                    inputSize.getHeight());

            final int orientation = getResources().getConfiguration().orientation;
            if (orientation == Configuration.ORIENTATION_LANDSCAPE) {
                autoFitTextureView.setAspectRatio(previewSize.getWidth(), previewSize.getHeight());
            } else {
                autoFitTextureView.setAspectRatio(previewSize.getHeight(), previewSize.getWidth());
            }
        } catch (final CameraAccessException cae) {
            cae.printStackTrace();
        }

        connectionCallback.onPreviewSizeChosen(previewSize, sensorOrientation);
    }

    // íšŒì „ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë©”ì†Œë“œ
    private void configureTransform(final int viewWidth, final int viewHeight) {
        final Activity activity = getActivity();
        if (null == autoFitTextureView || null == previewSize || null == activity) {
            return;
        }

        final int rotation = activity.getWindowManager().getDefaultDisplay().getRotation();
        final Matrix matrix = new Matrix();
        final RectF viewRect = new RectF(0, 0, viewWidth, viewHeight);
        final RectF bufferRect =
                new RectF(0, 0, previewSize.getHeight(), previewSize.getWidth());
        final float centerX = viewRect.centerX();
        final float centerY = viewRect.centerY();
        if (Surface.ROTATION_90 == rotation || Surface.ROTATION_270 == rotation) {
            bufferRect.offset(
                    centerX - bufferRect.centerX(),
                    centerY - bufferRect.centerY());
            matrix.setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL);
            final float scale = Math.max(
                    (float) viewHeight / previewSize.getHeight(),
                    (float) viewWidth / previewSize.getWidth());
            matrix.postScale(scale, scale, centerX, centerY);
            matrix.postRotate(90 * (rotation - 2), centerX, centerY);
        } else if (Surface.ROTATION_180 == rotation) {
            matrix.postRotate(180, centerX, centerY);
        }
        autoFitTextureView.setTransform(matrix);
    }
    // ì¹´ë©”ë¼ì˜ í¬ê¸°ë¥¼ ì„¤ì •í•˜ëŠ” ë©”ì†Œë“œ
    // ì •ì‚¬ê°í˜•í˜•íƒœë¡œ ë§Œë“¤ê¸° ìœ„í•´ì„œ ë„ˆë¹„ì™€ ë†’ì´ ì¤‘ì—ì„œ ì‘ì€ ê²ƒì„ ì„ íƒí•˜ì—¬ ë¹„ìœ¨ì„ ì¡°ì •
    protected Size chooseOptimalSize(final Size[] choices, final int width, final int height) {
        final int minSize = Math.min(width, height);
        final Size desiredSize = new Size(width, height);

        final List<Size> bigEnough = new ArrayList<Size>();
        final List<Size> tooSmall = new ArrayList<Size>();
        for (final Size option : choices) {
            if (option.equals(desiredSize)) {
                return desiredSize;
            }

            if (option.getHeight() >= minSize && option.getWidth() >= minSize) {
                bigEnough.add(option);
            } else {
                tooSmall.add(option);
            }
        }

        if (bigEnough.size() > 0) {
            return Collections.min(bigEnough, new CompareSizesByArea());
        } else {
            return Collections.max(tooSmall, new CompareSizesByArea());
        }
    }
    
    // ì¹´ë©”ë¼ì˜ ìƒíƒœê°€ ë³€ê²½ë  ë•Œ í˜¸ì¶œë˜ëŠ” ë¦¬ìŠ¤ë„ˆ
    private final CameraDevice.StateCallback stateCallback = new CameraDevice.StateCallback() {
        // ì„¸ë§ˆí¬ì–´ë¥¼ ì·¨ë“í•´ì„œ ë½ì„ í•´ì œ
        @Override
        public void onOpened(final CameraDevice cd) {
            cameraOpenCloseLock.release();
            cameraDevice = cd;
            createCameraPreviewSession();
        }

        @Override
        public void onDisconnected(final CameraDevice cd) {
            cameraOpenCloseLock.release();
            cd.close();
            cameraDevice = null;
        }

        @Override
        public void onError(final CameraDevice cd, final int error) {
            cameraOpenCloseLock.release();
            cd.close();
            cameraDevice = null;
            final Activity activity = getActivity();
            if (null != activity) {
                activity.finish();
            }
        }
    };
    
    // ì¹´ë©”ë¼ ì‚¬ìš© ê¶Œí•œì„ ì·¨ë“í•˜ê³  ì‚¬ìš©í•˜ê¸° ì§ì „ì— í˜¸ì¶œí•˜ê¸° ìœ„í•œ ë©”ì†Œë“œ
    // ë¯¸ë¦¬ë³´ê¸° ì™€ ì¹´ë©”ë¼ì— ê´€ë ¨ëœ ì„¤ì •ì„ ìˆ˜í–‰
    private void createCameraPreviewSession() {
        try {
            final SurfaceTexture texture = autoFitTextureView.getSurfaceTexture();
            texture.setDefaultBufferSize(previewSize.getWidth(), previewSize.getHeight());

            final Surface surface = new Surface(texture);

            // ë¯¸ë¦¬ë³´ê¸° í¬ë§·ì„ ì„¤ì • yuv ì—ì„œ rgb ë¡œ ë³€ê²½ í•´ì•¼ í•¨
            previewReader = ImageReader.newInstance(previewSize.getWidth(),
                    previewSize.getHeight(), ImageFormat.YUV_420_888, 2);
            previewReader.setOnImageAvailableListener(imageAvailableListener,
                    backgroundHandler);

            previewRequestBuilder = cameraDevice.createCaptureRequest(
                    CameraDevice.TEMPLATE_PREVIEW);
            previewRequestBuilder.addTarget(surface);
            previewRequestBuilder.addTarget(previewReader.getSurface());

            previewRequestBuilder.set(
                    CaptureRequest.CONTROL_AF_MODE,
                    CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE);
            previewRequestBuilder.set(
                    CaptureRequest.CONTROL_AE_MODE,
                    CaptureRequest.CONTROL_AE_MODE_ON_ALWAYS_FLASH);
            previewRequestBuilder.set(
                    CaptureRequest.FLASH_MODE,
                    CameraMetadata.FLASH_MODE_TORCH);

            cameraDevice.createCaptureSession(
                    Arrays.asList(surface, previewReader.getSurface()),
                    sessionStateCallback,
                    null);
        } catch (final CameraAccessException e) {
            e.printStackTrace();
        }
    }

    // ì¹´ë©”ë¼ í™”ë©´ì„ ê°€ì ¸ì˜¨ í›„ í˜¸ì¶œë˜ëŠ” ë¦¬ìŠ¤ë„ˆ
    private final CameraCaptureSession.StateCallback sessionStateCallback =
            new CameraCaptureSession.StateCallback() {
                // ì„¤ì •ì— ì„±ê³µí•œ ê²½ìš°
                @Override
                public void onConfigured(final CameraCaptureSession cameraCaptureSession) {
                    if (null == cameraDevice) {
                        return;
                    }

                    captureSession = cameraCaptureSession;
                    try {
                        captureSession.setRepeatingRequest(previewRequestBuilder.build(),
                                null, backgroundHandler);
                    } catch (final CameraAccessException e) {
                        e.printStackTrace();
                    }
                }
                // ì„¤ì •ì— ì‹¤íŒ¨í•œ ê²½ìš°
                @Override
                public void onConfigureFailed(final CameraCaptureSession cameraCaptureSession) {
                    Toast.makeText(getActivity(), "CameraCaptureSession Failed", Toast.LENGTH_SHORT).show();
                }
            };
    
    // ì¹´ë©”ë¼ ì¢…ë£Œí•˜ëŠ” ë©”ì†Œë“œ
    // ì´ ë©”ì†Œë“œëŠ” êµ¬í˜„í•˜ì§€ ì•Šì•„ë„ ì• í”Œë¦¬ì¼€ì´ì…˜ ìì²´ì— ì•„ë¬´ëŸ° ì˜í–¥ë„ ì—†ìŒ
    private void closeCamera() {
        try {
            cameraOpenCloseLock.acquire();
            if (null != captureSession) {
                captureSession.close();
                captureSession = null;
            }
            if (null != cameraDevice) {
                cameraDevice.close();
                cameraDevice = null;
            }
            if (null != previewReader) {
                previewReader.close();
                previewReader = null;
            }
        } catch (final InterruptedException e) {
            throw new RuntimeException("Interrupted while trying to lock camera closing.", e);
        } finally {
            cameraOpenCloseLock.release();
        }
    }

    public interface ConnectionCallback {
        void onPreviewSizeChosen(Size size, int cameraRotation);
    }

    // java ëŠ” í¬ê¸°ë¹„êµë¥¼ í•  ë•Œ ìˆ«ì ë°ì´í„°ëŠ” ë¶€ë“±í˜¸ë¡œ í•˜ì§€ë§Œ
    // ìˆ«ì ë°ì´í„°ê°€ ì•„ë‹Œ ê²½ìš°ëŠ” comparator ì˜ compare ë©”ì†Œë“œë¥¼ ì´ìš©
    // í¬ê¸° ë¹„êµë¥¼ í•´ì„œ ì •ë ¬ì„ í•˜ê³ ì í•  ë•Œ êµ¬í˜„í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤ê°€ Comparator ì™€ Comparable
    static class CompareSizesByArea implements Comparator<Size> {
        @Override
        public int compare(final Size lhs, final Size rhs) {
            return Long.signum(
                    (long) lhs.getWidth() * lhs.getHeight() - (long) rhs.getWidth() * rhs.getHeight());
        }
    }
}
```



### ğŸ“Œdeprecated

![image](https://user-images.githubusercontent.com/58774664/135380461-28ec4c20-b710-40a9-b975-d1bbba016d0f.png)

- Fragment ì— ì·¨ì†Œì„ ì´ ìƒê²¨ìˆê³  ì´ ì˜ë¯¸ëŠ” Fragment API 28ì—ì„œ deprecated ë˜ì—ˆë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤. 
- deprecated ë¶€ë¶„ì— ì·¨ì†Œì„ ì´ ë§Œë“¤ì–´ì§€ê³  ì·¨ì†Œì„ ì— ì»¤ì„œë¥¼ ê°–ë‹¤ëŒ€ë©´ ì •ë³´ê°€ ì¶œë ¥ë©ë‹ˆë‹¤
- ëŒ€ì²´í•˜ëŠ” í´ë˜ìŠ¤ë‚˜ ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•
- ë‹¤ë¥¸ í•˜ë‚˜ëŠ” build.gradle íŒŒì¼ì—ì„œ deprecated ì´ì „ ë²„ì „ìœ¼ë¡œ minsdk ë¥¼ ìˆ˜ì •í•˜ëŠ” ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤.



#### ì·¨ì†Œì„ ì„ ì—†ì• ëŠ” ë°©ë²•

- ëŒ€ì²´ê°€ëŠ¥í•˜ëŠ” ìƒˆë¡œìš´ í´ë˜ìŠ¤ë‚˜ ë©”ì†Œë“œë¡œ ë³€ê²½í•˜ê¸°

- ë²„ì „ì„ ë‚®ì¶”ê¸°

  - module ìˆ˜ì¤€ì˜ build.gradle ë¡œ ê°€ê¸°

  - minSdk ë¶€ë¶„ì´ 29ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

    ```
    android {
        compileSdk 31
    
        defaultConfig {
            applicationId "com.lpin.realtime_camera"
            minSdk 29
            targetSdk 31
            versionCode 1
            versionName "1.0"
    
            testInstrumentationRunner "androidx.test.runner.AndroidJUnitRunner"
        }
        
        ..ì¤‘ëµ..
    }
    ```

    

  - ì´ë¥¼ 28ë¡œë„ ë‚®ì¶°ë³´ê³  ê·¸ë˜ë„ ì·¨ì†Œì„ ì´ ì•ˆì—†ì–´ì§€ë©´ 27 ë¡œ ë³€ê²½í•´ë´…ë‹ˆë‹¤.(ë³€ê²½í•˜ê³  Sync Nowë¥¼ í•´ì•¼ í•©ë‹ˆë‹¤)

  - ì·¨ì†Œì„ ì´ ì‚¬ë¼ì§‘ë‹ˆë‹¤.

    ![image](https://user-images.githubusercontent.com/58774664/135380735-3131c273-51ea-43ea-9d39-ca8f3b4847c6.png)



### Callback ê³¼ Listener

- ì¼ë°˜ì ìœ¼ë¡œ Callbackì´ë‚˜ Listenerë¼ëŠ” ìš©ì–´ëŠ” ì´ë²¤íŠ¸ê°€ ë°œìƒí–ˆì„ ë•Œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ë‚˜ í´ë˜ìŠ¤ ë˜ëŠ” ì¸í„°í˜ì´ìŠ¤ì— ë¶™ì´ëŠ” ë‹¨ì–´ì…ë‹ˆë‹¤.
- íŠ¹íˆ Listener ëŠ” javaì—ì„œëŠ” Interfaceë¡œ í•œì •í•©ë‹ˆë‹¤.
- ì´ ê²½ìš° êµ¬í˜„í•´ì•¼ í•˜ëŠ” ë©”ì†Œë“œê°€ í•˜ë‚˜ë¼ë©´ lambdaë¡œ ëŒ€ì²´ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤
  `->` ë¼ëŠ” í‘œí˜„ì´ ë³´ì´ë©´ lambdaì…ë‹ˆë‹¤.

```java
private ConnectionCallback connectionCallback;
private ImageReader.OnImageAvailableListener imageAvailableListener;
```



### ì¹´ë©”ë¼ ì•„ì´ë”” 

- ì¹´ë©”ë¼ ì•„ì´ë””
  - 0 : í›„ë©´ì¹´ë©”ë¼
  - 1: ì „ë©´ ì¹´ë©”ë¼

```java
// ì¹´ë©”ë¼ í¬ê¸°
private Size inputSize;
// ì¹´ë©”ë¼ ì•„ì´ë””
// 0 : í›„ë©´ì¹´ë©”ë¼, 1: ì „ë©´ ì¹´ë©”ë¼
private String cameraId;
```



### Thread ì‚¬ìš©ì„ ìœ„í•œ ë³€ìˆ˜ âœ¨

- Handler ëŠ” ì•ˆë“œë¡œì´ë“œì—ì„œ ë©”ì‹œì§€ íì— ëª…ë ¹ì„ ì „ë‹¬í•´ì„œ ìˆ˜í–‰í•˜ë„ë¡ í•´ì£¼ëŠ” ê°ì²´ë¡œ thread ë¡œ ì‘ì—…í•œ í›„ ê²°ê³¼ë¥¼ í™”ë©´ì— ì¶œë ¥í•˜ê³ ì í•  ë•Œ ì£¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ë©”ì¸ ìŠ¤ë ˆë“œë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ìŠ¤ë ˆë“œëŠ” í™”ë©´ ê°±ì‹ ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
- ê±°ì˜ ëŒ€ë‹¤ìˆ˜ëŠ” GUI ì‹œìŠ¤í…œì´ ë§ˆì°¬ê°€ì§€ì´ë©° í•˜ë‚˜ì˜ ë©”ì†Œë“œ ì•ˆì— ì¶œë ¥ì„ ì—¬ëŸ¬ ë²ˆ í•˜ëŠ” ì½”ë“œê°€ ì¡´ì¬í•˜ë©´ ëª¨ì•„ì„œ í•œë²ˆì— ì²˜ë¦¬í•©ë‹ˆë‹¤

```java
// thread ì‚¬ìš©ì„ ìœ„í•œ ë³€ìˆ˜
private HandlerThread backgroundThread = null;
private Handler backgroundHandler = null;
```



### ìƒì„±ì

ìƒì„±ìì˜ ì ‘ê·¼ ì§€ì •ìë¥¼  privateìœ¼ë¡œ ì§€ì •í•˜ì—¬ ì™¸ë¶€ì—ì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ì„ ëª»í•˜ê²Œ í•©ë‹ˆë‹¤. 

```java
// ìƒì„±ìì˜ ì ‘ê·¼ ì§€ì •ì private : ì™¸ë¶€ì—ì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ì„ ëª»í•¨
private CameraFragment(final ConnectionCallback callback,
                       final ImageReader.OnImageAvailableListener imageAvailableListener,
                       final Size inputSize,
                       final String cameraId) {
    this.connectionCallback = callback;
    this.imageAvailableListener = imageAvailableListener;
    this.inputSize = inputSize;
    this.cameraId = cameraId;
}
```

ìƒì„±ìë¥¼ ì´ìš©í•˜ì§€ ì•Šê³  ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ì„œ ë¦¬í„´í•´ì£¼ëŠ” static ë©”ì†Œë“œ(íŒ©í† ë¦¬ íŒ¨í„´) ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. 

```java
// ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ì„œ ë¦¬í„´í•´ì£¼ëŠ” static ë©”ì†Œë“œ - íŒ©í† ë¦¬ íŒ¨í„´
// ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±ìë¥¼ ì´ìš©í•˜ì§€ ì•Šê³  ë³„ë„ì˜ ë©”ì†Œë“œì—ì„œ ìƒì„±
// ê·¸ ì´ìœ ëŠ” ìƒì„±í•˜ëŠ” ê³¼ì •ì´ ë³µì¡í•´ì„œ ìƒì„±ìë¥¼ ë…¸ì¶œì‹œí‚¤ì§€ ì•Šê¸° ìœ„í•œ ëª©ì ê³¼ íš¨ìœ¨ì„ ìœ„í•´ì„œì„
public static CameraFragment newInstance(
    final ConnectionCallback callback,
    final ImageReader.OnImageAvailableListener imageAvailableListener,
    final Size inputSize,
    final String cameraId) {
    return new CameraFragment(callback, imageAvailableListener, inputSize, cameraId);
}
```

- ìœ„ì™€ ê°™ì´ í•˜ëŠ” ì´ìœ ëŠ”  **ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì´ ë³µì¡í•´ì„œ ìƒì„±ìë¥¼ ë…¸ì¶œì‹œí‚¤ì§€ ì•Šê¸° ìœ„í•¨**ê³¼ **íš¨ìœ¨ì„ ìœ„í•´ì„œ**ì…ë‹ˆë‹¤.

- ìê¸° ìì‹ ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ë¦¬í‚¬ ìˆ˜ ìˆëŠ” static ë³€ìˆ˜ê°€ ì¡´ì¬í•˜ê³  ê·¸ ë³€ìˆ˜ê°€ null ì¼ ë•Œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì½”ë“œê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤.

- ì‹±ê¸€í†¤ì€ ì¸ìŠ¤í„´ìŠ¤ë¥¼ 1ê°œë§Œ ìƒì„±í•  ìˆ˜ ìˆëŠ” í´ë˜ìŠ¤



MLì„ í”„ë¡œê·¸ë˜ë¨¸ê°€ í•´ì£¼ëŠ” ì´ìœ ì…ë‹ˆë‹¤.



# 10.ë””ìì¸ ìˆ˜ì •

activity_main.xml íŒŒì¼ì˜ ë””ìì¸ì„ ìˆ˜ì •

Fragmentë¥¼ ì¶œë ¥ë  ë•Œ 

```xml
<?xml version="1.0" encoding="utf-8"?>
<androidx.constraintlayout.widget.ConstraintLayout xmlns:android="http://schemas.android.com/apk/res/android"
    xmlns:app="http://schemas.android.com/apk/res-auto"
    xmlns:tools="http://schemas.android.com/tools"
    android:layout_width="match_parent"
    android:layout_height="match_parent"
    tools:context=".MainActivity">

    <FrameLayout
        android:id="@+id/fragment"
        android:layout_width="match_parent"
        android:layout_height="wrap_content"
        app:layout_constraintTop_toTopOf="parent"
        />

    <TextView
        android:id="@+id/textView"
        android:layout_width="wrap_content"
        android:layout_height="wrap_content"
        android:text="Result"
        app:layout_constraintTop_toBottomOf="@id/fragment"
        app:layout_constraintBottom_toBottomOf="parent"
        app:layout_constraintLeft_toLeftOf="parent"
        app:layout_constraintRight_toRightOf="parent" />

</androidx.constraintlayout.widget.ConstraintLayout>
```



# 11.MainActivity

ê¶Œí•œ ì„¤ì •

## 2) ì „ì²´ ì†ŒìŠ¤



```java
package com.lpin.realtime_camera;


import androidx.annotation.NonNull;
import androidx.appcompat.app.AppCompatActivity;

import android.Manifest;
import android.app.Fragment;
import android.content.Context;
import android.content.pm.PackageManager;
import android.graphics.Bitmap;
import android.hardware.camera2.CameraAccessException;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraManager;
import android.media.Image;
import android.media.ImageReader;
import android.os.Bundle;
import android.os.Handler;
import android.os.HandlerThread;
import android.util.Log;
import android.util.Pair;
import android.util.Size;
import android.view.Surface;
import android.view.WindowManager;
import android.widget.TextView;
import android.widget.Toast;

import java.io.IOException;
import java.util.Locale;

public class MainActivity extends AppCompatActivity {
    public static final String TAG = "[IC]MainActivity";

    //ì¹´ë©”ë¼ ì‚¬ìš© ê¶Œí•œì„ ìœ„í•œ ë³€ìˆ˜
    private static final String CAMERA_PERMISSION = Manifest.permission.CAMERA;
    //ì‚¬ìš© ê¶Œí•œì„ ìš”ì²­í•˜ê³  êµ¬ë¶„í•˜ê¸° ìœ„í•œ ë³€ìˆ˜
    private static final int PERMISSION_REQUEST_CODE = 1;

    //ê²°ê³¼ë¥¼ ì¶œë ¥í•  í…ìŠ¤íŠ¸ ë·°
    private TextView textView;
    //ë¶„ë¥˜ê¸°
    private Classifier cls;

    private HandlerThread handlerThread;
    // thread ê°€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë‹¤ê°€ í™”ë©´ ì¶œë ¥ì„ í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ê°œê°œ=
    private Handler handler;
    // ì¹´ë©”ë¼ ë¯¸ë¦¬ë³´ê¸°ì˜ í¬ê¸°
    private int previewWidth = 0;
    private int previewHeight = 0;
    // ì¹´ë©”ë¼ ì´ë¯¸ì§€
    private Bitmap rgbFrameBitmap = null;
    // ì‘ì—… ì¤‘ì¸ì§€ í™•ì¸
    // boolean ë³€ìˆ˜ëŠ” ì•ì— isë¥¼ ë¶™ì—¬ì„œ êµ¬ë¶„
    private boolean isProcessingFrame = false;
    // ê¸°ê¸° ë°©í–¥ì„ ìœ„í•œ ë³€ìˆ˜
    private int sensorOrientation = 0;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(null);
        setContentView(R.layout.activity_main);

        // ì•¡í‹°ë¹„í‹°ê°€ ì‹¤í–‰ë˜ëŠ” ë™ì•ˆ í™”ë©´ì´ ê³„ì† ì¼œì ¸ ìˆë„ë¡ ì„¤ì •
        // ì•ˆë“œë¡œì´ë“œë‚˜  ì¹´ë©”ë¼ëŠ” ì¼ì •ì‹œê°„ ì´í›„ ì €ì ˆë¡œ í™”ë©´ì´ êº¼ì§
        getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);

        textView = findViewById(R.id.textView);

        try {
            cls = new Classifier(this);
            cls.init();
        } catch (IOException ioe) {
            ioe.printStackTrace();
        }
        
        // ë™ì  ì›í•œì„ ì„¤ì •
        if(checkSelfPermission(CAMERA_PERMISSION) == PackageManager.PERMISSION_GRANTED) {
            //Fragment ì„¤ì •ì„ ìœ„í•œ ë©”ì†Œë“œ í˜¸ì¶œ
            setFragment();
        } else {
            requestPermissions(new String[]{CAMERA_PERMISSION}, PERMISSION_REQUEST_CODE);
        }
    }

    //ë™ì  ê¶Œí•œ ìš”ì²­ì„ í•œ í›„ ì„ íƒí•˜ë©´ í˜¸ì¶œë˜ëŠ” ì½œë°± ë©”ì†Œë“œ
    @Override
    public void onRequestPermissionsResult(
            int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {
        if(requestCode == PERMISSION_REQUEST_CODE) {
            // ê¶Œí•œ ì‚¬ìš©ì„ í—ˆê°€í•˜ë©´ í˜¸ì¶œ
            if(grantResults.length > 0 && allPermissionsGranted(grantResults)) {
                setFragment();
            }
            // ê¶Œí•œ ì‚¬ìš©ì„ ì·¨ì†Œí•˜ë©´ í˜¸ì¶œ
            else {
                Toast.makeText(this, "permission denied", Toast.LENGTH_LONG).show();
            }
        }
        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
    }

    //ì—¬ëŸ¬ ê¶Œí•œì„ ìš”ì²­í•œ ê²½ìš° ëª¨ë“  ê¶Œí•œì„ í™•ì¸í•˜ëŠ” ì‚¬ìš©ì ì •ì˜ ë©”ì†Œë“œ
    private boolean allPermissionsGranted(final int[] grantResults) {
        for (int result : grantResults) {
            if (result != PackageManager.PERMISSION_GRANTED) {
                return false;
            }
        }
        return true;
    }

    protected void setFragment() {
        Size inputSize = cls.getModelInputSize();
        String cameraId = chooseCamera();

        if(inputSize.getWidth() > 0 && inputSize.getHeight() > 0 && !cameraId.isEmpty()) {
            Fragment fragment = CameraFragment.newInstance(
                    (size, rotation) -> {
                        previewWidth = size.getWidth();
                        previewHeight = size.getHeight();
                        sensorOrientation = rotation - getScreenOrientation();
                    },
                    reader->processImage(reader),
                    inputSize,
                    cameraId);

            Log.d(TAG, "inputSize : " + cls.getModelInputSize() +
                    "sensorOrientation : " + sensorOrientation);
            getFragmentManager().beginTransaction().replace(
                    R.id.fragment, fragment).commit();
        } else {
            Toast.makeText(this, "Can't find camera", Toast.LENGTH_SHORT).show();
        }
    }

    private String chooseCamera() {
        final CameraManager manager =
                (CameraManager)getSystemService(Context.CAMERA_SERVICE);
        try {
            for (final String cameraId : manager.getCameraIdList()) {
                final CameraCharacteristics characteristics =
                        manager.getCameraCharacteristics(cameraId);

                final Integer facing = characteristics.get(CameraCharacteristics.LENS_FACING);
                if (facing != null && facing == CameraCharacteristics.LENS_FACING_BACK) {
                    return cameraId;
                }
            }
        } catch (CameraAccessException e) {
            e.printStackTrace();
        }

        return "";
    }

    protected int getScreenOrientation() {
        switch (getWindowManager().getDefaultDisplay().getRotation()) {
            case Surface.ROTATION_270:
                return 270;
            case Surface.ROTATION_180:
                return 180;
            case Surface.ROTATION_90:
                return 90;
            default:
                return 0;
        }
    }

    protected void processImage(ImageReader reader) {
        if (previewWidth == 0 || previewHeight == 0) {
            return;
        }

        if(rgbFrameBitmap == null) {
            rgbFrameBitmap = Bitmap.createBitmap(
                    previewWidth,
                    previewHeight,
                    Bitmap.Config.ARGB_8888);
        }

        if (isProcessingFrame) {
            return;
        }

        isProcessingFrame = true;

        final Image image = reader.acquireLatestImage();
        if (image == null) {
            isProcessingFrame = false;
            return;
        }

        YuvToRGBConverter.yuvToRgb(this, image, rgbFrameBitmap);

        runInBackground(() -> {
            if (cls != null && cls.isInitialized()) {
                final Pair<String, Float> output = cls.classify(rgbFrameBitmap, sensorOrientation);

                runOnUiThread(() -> {
                    String resultStr = String.format(Locale.ENGLISH,
                            "class : %s, prob : %.2f%%",
                            output.first, output.second * 100);
                    textView.setText(resultStr);
                });
            }
            image.close();
            isProcessingFrame = false;
        });
    }

    // synchronized ëŠ” ë™ê¸°í™” ë©”ì†Œë“œë¥¼ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.
    // ì´ ë©”ì†Œë“œëŠ” ë™ì‹œì— í˜¸ì¶œë˜ê¸° ì•ŠìŒ
    protected synchronized void runInBackground(final Runnable r) {
        if (handler != null) {
            // ë©”ì‹œì§€ íì— ë¯¸ì‹œì§€ë¥¼ ì „ë‹¬
            // POST ë¡œ í˜¸ì¶œí•˜ë©´ ë‹¤ë¥¸ ì‘ì—…ì´ ì—†ì„ ë•Œ ì‘ì—…ì„ ìˆ˜í–‰
            handler.post(r);
        }
    }
}
```





## 2) Camera2 API

![image](https://user-images.githubusercontent.com/58774664/135365488-f0e7f827-261c-4d54-bc35-e2a264ae2955.png)



New - [Project from Version Control] - 

URL : https://github.com/itggangpae/Realtime_Image_Classfication.git  ì…ë ¥