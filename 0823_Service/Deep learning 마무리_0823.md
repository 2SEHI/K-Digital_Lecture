# ML, DL

ANN(인공 신경망:Machine Learning) => DNN => CNN => RNN => Attension => Transformer 

- DNN부터 딥러닝이라고 합니다.





# Auto Encoder

- Encoder나 Decoder라는 단어가 등장하면 생성 모델입니다. 대부분의 자연어 처리는 생성 모델입니다.

- 생성이란 의미는 입력을 받아서 입력을 기반으로 하는 새로운 무엇인가를 만들어내는 모델을 의미합니다.

- Auto Encoder는 입력데이터의 차원보다 낮은 차원으로 압축을 하기 때문에 효율적인 인코딩 또는 특성 학습, 표현 학습의 범주에서 속하며 크게 얘기할 때는 차원 축소의 한 방법이라고 합니다. PCA가 이의 큰 개념이라고 보면 되겠습니다.

- 압축을 했다가 복원을 하면 일정 부분 손실이 발생할 수 밖에 없는데 이 방법을 이용해서 새로운 샘플을 만들 수 있고 잡음이 섞인 데이터에서 잡음을 제거하는 효과도 만들어 낼 수 있습니다.





- AutoEncoder로는 이미지의 잡음제거를 할 수 있고 Convolution AutoEncoder(합성곱 오토인코더)를 이용하면 노이즈를 추가해서 훈련시키고 출력시 잡음을 제거합니다.

- 스트라이드는 옆으로 움직이는 거리임



### Auto Encdoer => CNN을 이용한 Auto Encoder => VAE => Semantic Segmentation -> GAN -> GAN의 변형모델



- Auto Encdoer

- CNN을 이용한 Auto Encoder

- VAE (Variational AutoEncoder) : 잠배 변수 부분을 정규 분포로 강제로 맞춰주는 방식

- Semantic Segmentation : 입력으로 얻은 정보를 추상화해서 모델링. 대표적인 예가 인공위성이나 비행기가 찍은 사진을 기반으로 지도를 생성하거나, 세포 구분 등에서 활용

- 생성적 적대 신경망(GAN) : 생성자와 판별자의 개념을 가짐. 생성자는 새로운 출력을 만들고 판별자는 새로운 출력을 거짓이라고 판별해내는 역할을 수행하는데 생성자는 판별자가 새로운 출력이라고 판단하지 못하도록 계속 생성해서 나중에 새로운 출력이라고 판단하지 못하는 데이터를 만들어 냅니다. 비지도 학습입니다.

- GAN의 변형모델 : DCGAN, SRGAN, CycleGAN





## Keras와 PyTorch 중에 무엇을 사용해야 할까?

- 딥러닝을 학습할 때 Keras냐 PyTorch냐는 중요한 문제가 아닙니다. 기본적인 모델의 개념과 전이학습을 하는 이유 등이 중요합니다. 수학적인 기반 지식이 없어도 모델을 만들어서 활용하는 것을 할 수 있습니다. 대기업이나 스타트 기업에 가는 경우에는 새로운 모델을 만들어야 하는 경우가 발생하는데 이때는 수학적인 개념이 중요합니다

- 분야를 결정한 것인지 아니면 기업 규모를 선책할 것인지 

- 대기업은 코딩테스트를 봐야하는 대신 직접 만든 프로젝트는 보지 않고 스타트업은 코딩테스트는 안보지만 직접 만든 프로젝트가 중요함.